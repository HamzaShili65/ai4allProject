{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /Users/hamza/Library/Python/3.9/lib/python/site-packages (2.2.1)\n",
      "Requirement already satisfied: seaborn in /Users/hamza/Library/Python/3.9/lib/python/site-packages (0.13.2)\n",
      "Requirement already satisfied: matplotlib in /Users/hamza/Library/Python/3.9/lib/python/site-packages (3.8.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/hamza/Library/Python/3.9/lib/python/site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: numpy in /Users/hamza/Library/Python/3.9/lib/python/site-packages (1.26.3)\n",
      "Requirement already satisfied: xgboost in /Users/hamza/Library/Python/3.9/lib/python/site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/hamza/Library/Python/3.9/lib/python/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/hamza/Library/Python/3.9/lib/python/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/hamza/Library/Python/3.9/lib/python/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/hamza/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/hamza/Library/Python/3.9/lib/python/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/hamza/Library/Python/3.9/lib/python/site-packages (from matplotlib) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/hamza/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/hamza/Library/Python/3.9/lib/python/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/hamza/Library/Python/3.9/lib/python/site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/hamza/Library/Python/3.9/lib/python/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/hamza/Library/Python/3.9/lib/python/site-packages (from matplotlib) (6.4.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/hamza/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/hamza/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/hamza/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (3.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/hamza/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas seaborn matplotlib scikit-learn numpy xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "df = pd.read_csv('./data/treated/biggerAugmentedData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                 0\n",
      "AGE                        0\n",
      "GENDER                     0\n",
      "VETERAN                    0\n",
      "INCOME                     0\n",
      "NIGHTS                     0\n",
      "substanceabuse             0\n",
      "completed                  0\n",
      "probation                  0\n",
      "assistancetype             0\n",
      "required                   0\n",
      "AT_RISK_OF_HOMELESSNESS    0\n",
      "INCOME_PER_NIGHT           0\n",
      "AGE_GROUP                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'inf' values with NaN to handle them as missing values\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "df['VETERAN'] = df['VETERAN'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "df['GENDER'] = df['GENDER'].apply(lambda x: 1 if x == 'Female' else 0)\n",
    "\n",
    "assistancetype_mapping = {\n",
    "    'noassistance': 0,\n",
    "    'tempassistance': 1,\n",
    "    'permassistance': 2,\n",
    "}\n",
    "\n",
    "# Use the map function to apply the mapping to the AGE_GROUP column\n",
    "df['assistancetype'] = df['assistancetype'].map(assistancetype_mapping)\n",
    "\n",
    "age_group_mapping = {\n",
    "    '18-25': 0,\n",
    "    '26-40': 1,\n",
    "    '41-55': 2,\n",
    "    '56-70': 3\n",
    "}\n",
    "\n",
    "# Use the map function to apply the mapping to the AGE_GROUP column\n",
    "df['AGE_GROUP'] = df['AGE_GROUP'].map(age_group_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>AGE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>VETERAN</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>NIGHTS</th>\n",
       "      <th>substanceabuse</th>\n",
       "      <th>completed</th>\n",
       "      <th>probation</th>\n",
       "      <th>assistancetype</th>\n",
       "      <th>required</th>\n",
       "      <th>AT_RISK_OF_HOMELESSNESS</th>\n",
       "      <th>INCOME_PER_NIGHT</th>\n",
       "      <th>AGE_GROUP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>47500</td>\n",
       "      <td>208</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>228.37</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12500</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49.21</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40000</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>181.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>262</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30000</td>\n",
       "      <td>331</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90.63</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  AGE  GENDER  VETERAN  INCOME  NIGHTS  substanceabuse  \\\n",
       "0           0   56       1        0   47500     208               1   \n",
       "1           1   69       0        0   12500     254               0   \n",
       "2           2   46       1        0   40000     221               0   \n",
       "3           3   32       0        0       0     262               1   \n",
       "4           4   60       1        0   30000     331               0   \n",
       "\n",
       "   completed  probation  assistancetype  required  AT_RISK_OF_HOMELESSNESS  \\\n",
       "0          0          0               0         1                        0   \n",
       "1          1          1               1         0                        0   \n",
       "2          1          1               2         0                        0   \n",
       "3          0          0               0         0                        0   \n",
       "4          1          0               1         1                        0   \n",
       "\n",
       "   INCOME_PER_NIGHT  AGE_GROUP  \n",
       "0            228.37          3  \n",
       "1             49.21          3  \n",
       "2            181.00          2  \n",
       "3              0.00          1  \n",
       "4             90.63          3  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomize the dataset\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "X = df.drop(['AT_RISK_OF_HOMELESSNESS'], axis=1)\n",
    "y = df['AT_RISK_OF_HOMELESSNESS']\n",
    "\n",
    "# Identifying categorical and numeric features\n",
    "categorical_features = []\n",
    "numeric_features = [col for col in X.columns if col not in categorical_features]\n",
    "\n",
    "# Preprocessing pipelines for both numeric and categorical data\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combining preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mX\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.865 0.861 0.849 0.857 0.86 ]\n",
      "Average CV Score: 0.8584\n"
     ]
    }
   ],
   "source": [
    "# Combine preprocessor and model into a single pipeline\n",
    "model_pipeline = make_pipeline(preprocessor, LogisticRegression(max_iter=1000, random_state=42))\n",
    "\n",
    "# Set up k-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Cross-validation scores\n",
    "cv_scores = cross_val_score(model_pipeline, X, y, cv=kf, scoring='accuracy')\n",
    "\n",
    "print(f\"Cross-Validation Scores: {cv_scores}\")\n",
    "print(f\"Average CV Score: {np.mean(cv_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score\n",
    "from sklearn.base import clone\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model_pipeline, X, y, cv=5):\n",
    "    \"\"\"\n",
    "    Evaluates a model pipeline using cross-validation and prints out average ROC-AUC, F1, Precision, and Recall scores.\n",
    "\n",
    "    Parameters:\n",
    "    - model_pipeline: The modeling pipeline that ends with a classifier.\n",
    "    - X: Feature matrix.\n",
    "    - y: Target vector.\n",
    "    - cv: Number of cross-validation folds.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary with average scores for ROC-AUC, F1, Precision, and Recall.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize KFold and lists to store metrics\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    auc_scores = []\n",
    "    f1_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "\n",
    "    # Perform cross-validation\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        # Clone the model pipeline for a fresh model each fold\n",
    "        clone_model = clone(model_pipeline)\n",
    "        \n",
    "        # Split the data\n",
    "        X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "        \n",
    "        # Fit the model\n",
    "        clone_model.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_fold = clone_model.predict(X_test_fold)\n",
    "        y_pred_proba_fold = clone_model.predict_proba(X_test_fold)[:, 1]\n",
    "        \n",
    "        # Calculate and store the metrics\n",
    "        auc_scores.append(roc_auc_score(y_test_fold, y_pred_proba_fold))\n",
    "        f1_scores.append(f1_score(y_test_fold, y_pred_fold))\n",
    "        precision_scores.append(precision_score(y_test_fold, y_pred_fold))\n",
    "        recall_scores.append(recall_score(y_test_fold, y_pred_fold))\n",
    "\n",
    "    # Calculate average scores\n",
    "    avg_scores = {\n",
    "        'ROC-AUC': np.mean(auc_scores),\n",
    "        'F1': np.mean(f1_scores),\n",
    "        'Precision': np.mean(precision_scores),\n",
    "        'Recall': np.mean(recall_scores)\n",
    "    }\n",
    "    \n",
    "    # Optionally, print the average scores\n",
    "    for score_name, score_value in avg_scores.items():\n",
    "        print(f\"Average {score_name} Score: {score_value:.4f}\")\n",
    "    \n",
    "    return avg_scores\n",
    "\n",
    "# # Example of using the function with a logistic regression pipeline\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Sample pipeline for demonstration\n",
    "# sample_pipeline = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "# # Invoke the evaluation function\n",
    "# # Ensure X and y are defined and hold your features and target variable, respectively\n",
    "# scores = evaluate_model(sample_pipeline, X, y, cv=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimized Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__C': 100, 'classifier__solver': 'lbfgs'}\n",
      "Best CV score: 0.85775\n",
      "Average ROC-AUC Score: 0.6532\n",
      "Average F1 Score: 0.3187\n",
      "Average Precision Score: 0.5253\n",
      "Average Recall Score: 0.2322\n"
     ]
    }
   ],
   "source": [
    "# Create a complete pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('classifier', LogisticRegression(max_iter=100))])\n",
    "\n",
    "# Define a grid of parameters to search over\n",
    "param_grid = {\n",
    "    'classifier__C': [40, 100, 500],\n",
    "    'classifier__solver': ['liblinear', 'lbfgs']\n",
    "}\n",
    "\n",
    "# Set up the grid search\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Splitting the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best CV score:\", grid_search.best_score_)\n",
    "\n",
    "best_lr_model = grid_search.best_estimator_\n",
    "evaluate_model(best_lr_model, X, y, cv=5)\n",
    "\n",
    "# Make predictions with the best found parameters\n",
    "y_pred = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Feature  Coefficient\n",
      "3            VETERAN     0.662204\n",
      "5             NIGHTS    -0.102441\n",
      "11  INCOME_PER_NIGHT    -0.071547\n",
      "8          probation     0.045928\n",
      "7          completed     0.039479\n",
      "6     substanceabuse    -0.033489\n",
      "9     assistancetype     0.016226\n",
      "4             INCOME    -0.011176\n",
      "2             GENDER     0.009954\n",
      "12         AGE_GROUP    -0.008306\n",
      "1                AGE     0.005221\n",
      "0         Unnamed: 0     0.004083\n",
      "10          required    -0.001873\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'best_pipeline' is your fitted pipeline object that includes the logistic regression model\n",
    "classifier = best_lr_model.named_steps['classifier']  # Access the logistic regression step\n",
    "\n",
    "# Assuming 'X' is your feature matrix DataFrame used in model fitting\n",
    "# Make sure 'X' reflects the preprocessed data structure that the model was trained on\n",
    "feature_names = X.columns  # Feature names as they appear after preprocessing, before fitting the model\n",
    "\n",
    "# Coefficients from the logistic regression model within the pipeline\n",
    "coefficients = classifier.coef_[0]\n",
    "\n",
    "# Create DataFrame for better visualization\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': coefficients\n",
    "}).sort_values(by='Coefficient', key=abs, ascending=False)  # Sorting by absolute value\n",
    "\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine (SVM):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'svc__C': 0.007, 'svc__kernel': 'linear'}\n",
      "Best CV score: 0.86625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hamza/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC-AUC Score: 0.6474\n",
      "Average F1 Score: 0.3319\n",
      "Average Precision Score: 0.3979\n",
      "Average Recall Score: 0.2849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ROC-AUC': 0.6473618312401597,\n",
       " 'F1': 0.3319292350645452,\n",
       " 'Precision': 0.3979488765203051,\n",
       " 'Recall': 0.28486555532010077}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Adjusting the pipeline to enable probability estimation in SVC\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svc', SVC(probability=True))  # Enable probability estimation\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'svc__C': [0.007, 0.01, 0.1],  # Regularization strength\n",
    "    'svc__kernel': ['linear', 'rbf']  # Kernel type\n",
    "}\n",
    "\n",
    "# Set up the grid search\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Splitting the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best CV score:\", grid_search.best_score_)\n",
    "\n",
    "best_svm_model = grid_search.best_estimator_\n",
    "evaluate_model(best_svm_model, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Feature  Coefficient\n",
      "12         AGE_GROUP    -0.000333\n",
      "1                AGE     0.000312\n",
      "3            VETERAN     0.000123\n",
      "5             NIGHTS    -0.000039\n",
      "8          probation    -0.000031\n",
      "11  INCOME_PER_NIGHT     0.000026\n",
      "2             GENDER    -0.000019\n",
      "10          required     0.000017\n",
      "7          completed    -0.000017\n",
      "0         Unnamed: 0    -0.000013\n",
      "6     substanceabuse     0.000012\n",
      "9     assistancetype     0.000009\n",
      "4             INCOME    -0.000003\n"
     ]
    }
   ],
   "source": [
    "# Assuming linear kernel and you want to extract coefficients\n",
    "best_svm_model = grid_search.best_estimator_['svc']\n",
    "coefs = best_svm_model.coef_.flatten()  # Flatten if it's multi-class\n",
    "\n",
    "# Feature names (assuming all numeric or you've manually encoded categories)\n",
    "feature_names = X.columns\n",
    "\n",
    "# Creating a DataFrame for easier interpretation\n",
    "svm_feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': coefs\n",
    "}).sort_values(by='Coefficient', key=abs, ascending=False)\n",
    "\n",
    "print(svm_feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 30, 'n_estimators': 100}\n",
      "Best CV score: 0.8638\n",
      "Average ROC-AUC Score: 0.6501\n",
      "Average F1 Score: 0.2456\n",
      "Average Precision Score: 0.4963\n",
      "Average Recall Score: 0.1633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ROC-AUC': 0.6500533730861002,\n",
       " 'F1': 0.2456443636832888,\n",
       " 'Precision': 0.49632194033356825,\n",
       " 'Recall': 0.16327194171520978}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees\n",
    "    'max_depth': [None, 10, 20, 30]  # Maximum depth of the trees\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best CV score:\", grid_search.best_score_)\n",
    "\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "evaluate_model(best_rf_model, X, y, cv=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting Machines (e.g., XGBoost):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200}\n",
      "Best CV score: 0.8642\n",
      "Average ROC-AUC Score: 0.6655\n",
      "Average F1 Score: 0.2141\n",
      "Average Precision Score: 0.5298\n",
      "Average Recall Score: 0.1381\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ROC-AUC': 0.6655078691059779,\n",
       " 'F1': 0.2141326368554933,\n",
       " 'Precision': 0.5298465423465424,\n",
       " 'Recall': 0.1380865236292445}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],  # Number of gradient boosted trees\n",
    "    'max_depth': [3, 6, 9],  # Maximum tree depth\n",
    "    'learning_rate': [0.01, 0.1]  # Learning rate\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss'), \n",
    "                           param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best CV score:\", grid_search.best_score_)\n",
    "\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "evaluate_model(best_xgb_model, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a fitted Random Forest or XGBoost model\n",
    "best_tree_model = grid_search.best_estimator_.named_steps['classifier']\n",
    "\n",
    "# Get feature names - For tree models, this might directly correspond to columns if no one-hot encoding transformation is needed\n",
    "feature_names = X.columns  # Adjust if you have transformed features\n",
    "\n",
    "# Feature importances\n",
    "importances = best_tree_model.feature_importances_\n",
    "\n",
    "# Map importances to features\n",
    "feature_importance = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "\n",
    "# Sort by importance\n",
    "feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(feature_importance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
